# MemSage Configuration
# Copy this file to your project root and customize as needed

[scan]
# Maximum cost in USD for LLM analysis
max_cost = 50.0
# Number of parallel workers for processing
parallel_workers = 4
# Minimum severity to report (low, medium, high, critical)
min_severity = "low"
# Maximum file size in MB to scan
max_file_size_mb = 10.0

[llm]
# LLM provider: "ollama" (default) or "anthropic"
provider = "ollama"
# Model to use:
# For Ollama: "codellama:7b", "mistral:latest", "llama2:7b", etc.
# For Anthropic: "claude-3-haiku-20240307", "claude-3-sonnet-20240229", "claude-3-opus-20240229"
model = "codellama:7b"

[output]
# Output format: "console", "json", "sarif", "html"
format = "console"
# Output file path (optional)
# path = "memsage-report.sarif" 